# ğŸŒŠ Flood Damage Detection Using Siamese U-Net++

**Author:** Dharmendra Singh Chaudhary
**Challenge:** Post-Flood Damage Cutouts Challenge â€” Nepal AI & CV Bootcamp

---

## ğŸ“Œ 1. Problem Summary

The task is to determine which areas were affected by flooding using **two large orthomosaic GeoTIFF images**:

* **Pre-Flood Orthomosaic**
* **Post-Flood Orthomosaic**

These images cover several square kilometers and contain spatial metadata such as **CRS**, **bounds**, and **geotransform parameters**.

### ğŸ¯ The goal of the challenge:

âœ” Detect flood-affected land areas
âœ” Segment flooded pixels tile-wise
âœ” Compute centroid coordinates (latitude/longitude)
âœ” Compute area lost (mÂ²)
âœ” Export a CSV report of affected tiles
âœ” Save pre- and post-flood tile cutouts

A major challenge: **No ground-truth segmentation masks were provided**, so I designed a **self-supervised pipeline** using pseudo-label generation + Siamese U-Net++.

---

## ğŸ§  2. Overall Project Pipeline

This section follows the workflow implemented in **flood_detection.ipynb**.

---

### **Step 1 â€” Explore & Load Orthomosaics**

* Used **Rasterio** to inspect orthomosaic metadata.
* Images were extremely large (10kâ€“40k pixels per dimension), so full loading was impossible.
* Used **streamed tile reading** with `rasterio.windows.Window`.

---

### **Step 2 â€” Align & Crop Pre/Post TIFFs**

A key challenge:

â— **The pre- and post-flood TIFFs had different shapes**, causing mismatches in tile generation.

I implemented **aligned overlapping crop** using:

```python
aalign_and_crop_to_overlap(pre, post, out_pre, out_post)
```

This produced:

* `pre_aligned.tif`
* `post_aligned.tif`

Both having identical:

* CRS
* resolution
* spatial extent
* dimensions

---

### **Step 3 â€” Tile Extraction Using Raster Windows**

* Split images into **512 Ã— 512 pixel tiles**.
* Raster windows avoid loading the entire TIFF.
* Each tile preserves geospatial metadata used later for computing:
  âœ” pixel area in mÂ²
  âœ” centroid coordinates

---

### **Step 4 â€” Pseudo-Mask Generation (Self-Supervised Change Detection)**

Since no ground-truth mask exists, I generated **pseudo labels** using two strategies:

### âœ” If NIR channel exists â€” NDWI

```
NDWI = (Green - NIR) / (Green + NIR)
```

* Compute NDWI for both pre and post images.
* Apply **Otsu threshold** to detect water.
* Flood mask = `Water_post AND (NOT Water_pre)`.

### âœ” If only RGB â€” Difference Masking

* Convert pre/post tiles to grayscale.
* Compute **absolute intensity difference**.
* Apply Gaussian smoothing.
* Apply Otsu threshold.

### âœ” Noise removal

* Morphological opening
* Minimum connected component area filtering

Pseudo masks were saved as:

```
tile_x_pre.png
tile_x_post.png
tile_x_mask.png
```

These masks served as **training labels** for the Siamese U-Net++.

---

## ğŸ§© 5. Dataset Loader (FloodDataset)

The custom PyTorch `FloodDataset` performs:

* Raster window extraction
* Padding of non-complete tiles
* Normalization to [0, 1]
* Pseudo-mask generation (NDWI or RGB diff)
* Returns:

  * Pre-flood tile
  * Post-flood tile
  * Pseudo-flood mask
  * Tile centroid
  * Tile grid index

This makes the pipeline memory-efficient and geospatially accurate.

---

## ğŸ”¥ 6. Model â€” **Siamese U-Net++**

I implemented a full **nested U-Net++ architecture** adapted to a Siamese setting.

### ğŸ”‘ Key Features

âœ” Shared encoder processes **pre-flood** and **post-flood** tiles using the same weights
âœ” Feature maps are **concatenated** to highlight changes
âœ” **Nested dense skip connections** (core of U-Net++)
âœ” **Deep supervision** using four output heads
âœ” Final segmentation = average of deep supervision outputs

This architecture is highly effective for **fine-grained change detection**.

---

## ğŸ‹ï¸ 7. Training Pipeline

### ğŸ“Œ Train/Val Split

Used a **spatial split** to prevent leakage:

* First 80% image rows â†’ **Training**
* Last 20% image rows â†’ **Validation**

This prevents the model from seeing nearby regions during validation.

### ğŸ“Œ Loss Function

A combination for stable segmentation:

* **BCEWithLogitsLoss**
* **Dice Loss**

### ğŸ“Œ Optimizer

* **AdamW**
* Learning rate = `1e-4`

### ğŸ“Œ Mixed Precision Training

Used:

```
torch.amp.autocast
GradScaler
```

for speed & lower memory usage.

### ğŸ“Œ Early Stopping

* Patience = 3 epochs
* Automatically saves the best checkpoint.

---

## ğŸ§Š 8. Inference Pipeline (GeoTIFF â†’ Mask â†’ CSV)

The inference script performs:

1. Load `pre_aligned.tif` and `post_aligned.tif`.
2. Slide 512Ã—512 window over full raster.
3. Predict mask using Siamese U-Net++.
4. Threshold mask.
5. Extract connected components.
6. Compute centroid in pixel coords.
7. Convert pixel coords â†’ lat/lon using geotransform.
8. Compute area in mÂ²:

```
area = positive_pixels Ã— (pixel_width Ã— pixel_height)
```

9. Save tile cutouts:

```
tile_x_pre.jpg
tile_x_post.jpg
```

10. Append to `affected.csv`:

| tile_id | longitude | latitude | area_m2 | pre_image | post_image |

---

## âš ï¸ 9. Time Constraints â€” Full Inference Not Completed

Although the entire inference pipeline is correctly implemented, **I could not run full inference** due to:

* Orthomosaics containing tens of thousands of tiles
* Limited Kaggle GPU runtime
* Heavy Siamese Nested U-Net++ architecture
* Slow tile-by-tile prediction
* Strict submission deadline

â¡ï¸ Therefore, I prepared the full pipeline but **could not finish generating the final CSV**.

---

## ğŸ§© 10. Key Challenges & Solutions

### **Challenge 1 â€” Mismatched Dimensions**

âœ” Solved via aligned overlapping cropping

### **Challenge 2 â€” No Ground Truth**

âœ” Solved by generating NDWI/RGB pseudo masks

### **Challenge 3 â€” Huge Raster Sizes**

âœ” Solved with raster window streaming

### **Challenge 4 â€” Spatial Leakage**

âœ” Avoided using spatial train/val split

### **Challenge 5 â€” Computing Geo-Area & Centroid**

âœ” Used raster transform + pixel resolution

### **Challenge 6 â€” Kaggle Time Limit**

âœ” Complete pipeline implemented but full inference incomplete

---

## ğŸ 11. Conclusion

This project successfully integrates:

* Geospatial raster processing
* Pseudo-label generation
* Change detection
* Siamese U-Net++ model
* Tile-based segmentation
* Geo-coordinate conversion
* Area estimation
* CSV reporting

Even without ground-truth segmentation masks, the system learned to detect flooded land using **self-supervision**.

### ğŸ’¡ What I Learned

* Handling large orthomosaic TIFFs
* Building geospatial ML pipelines
* Remote sensing change detection
* Siamese deep learning architectures
* Geographical coordinate and area computations

This challenge offered valuable experience building a **real-world disaster response solution**.

---

## ğŸ“š References

* Siamese Networks: [https://www.geeksforgeeks.org/nlp/siamese-neural-network-in-deep-learning/](https://www.geeksforgeeks.org/nlp/siamese-neural-network-in-deep-learning/)
* U-Net Architecture Explained: [https://www.geeksforgeeks.org/machine-learning/unet-architecture-explained/](https://www.geeksforgeeks.org/machine-learning/unet-architecture-explained/)
